{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('pytorch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fb220023fd2800431fe98a81f852d0ad5fc6056086b92ba5142182fcc04964c6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pivoz/Machine-Learning-Collection/blob/master/PersonReID_TensorExtractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6jMA8w_8oOH"
      },
      "source": [
        "[https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/DeepLearningProject.ipynb](https://colab.research.google.com/github/dadebulba/DeepLearningProject/blob/main/DeepLearningProject.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaPQ91Z78oOI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSxDvJ0D8oOK"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/UNITN/5Â° anno/Deep Learning 2021/dataset.zip\" -d dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg8kbiHv8oOL"
      },
      "source": [
        "# Deep Learning Project - People ReID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUDHglK08oOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acf7a7b-83cf-4873-f2dd-e46ca7d9b1e4"
      },
      "source": [
        "# import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image\n",
        "import random\n",
        "import gc\n",
        "random.seed(10)\n",
        "# print cuda info\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda device count: {torch.cuda.device_count()}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda available: True\n",
            "Cuda device count: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwZMA17l8oOX"
      },
      "source": [
        "# Network\n",
        "## Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9__1oD_z8oOX"
      },
      "source": [
        "'''\n",
        "Input arguments\n",
        "  num_classes: number of classes in the dataset.\n",
        "               This is equal to the number of output neurons.\n",
        "'''\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "class Siamese(nn.Module):\n",
        "\n",
        "    def __init__(self, resnet):\n",
        "        super(Siamese, self).__init__()\n",
        "        self.resnet = resnet\n",
        "        self.resnet.fc = Identity()\n",
        "        self.linear = torch.nn.Sequential(\n",
        "          torch.nn.Linear(in_features=2048, out_features=1024),\n",
        "          torch.nn.Linear(in_features=1024, out_features=512),\n",
        "          torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        out1 = self.forward_one(x1)\n",
        "        out2 = self.forward_one(x2)\n",
        "        return out1, out2\n",
        "\n",
        "def initialize_alexnet(num_classes):\n",
        "  # load the pre-trained Alexnet\n",
        "  #alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "  wide_resnet = torchvision.models.resnet50(pretrained=True)\n",
        "  num_features = wide_resnet.fc.in_features\n",
        "  wide_resnet.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=num_features, out_features=1024),\n",
        "    torch.nn.Linear(in_features=1024, out_features=512),\n",
        "    torch.nn.Linear(in_features=512, out_features=num_classes),\n",
        "    torch.nn.Sigmoid()\n",
        "  )\n",
        "  #print(resnext)\n",
        "  # get the number of neurons in the penultimate layer\n",
        "  #in_features = alexnet.classifier[6].in_features\n",
        "  \n",
        "  # re-initalize the output layer\n",
        "  #alexnet.classifier[6] = torch.nn.Sequential(\n",
        "  #  torch.nn.Linear(in_features=in_features, out_features=num_classes),\n",
        "  #  torch.nn.Sigmoid()\n",
        "  #)\n",
        "  return wide_resnet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fINP--L08oOQ"
      },
      "source": [
        "class PeopleTestDataset(Dataset):\n",
        "    def __init__(self, X1, X2, query_dir, test_dir):\n",
        "        self.X1 = X1\n",
        "        self.X2 = X2\n",
        "        self.query_dir = query_dir\n",
        "        self.test_dir = test_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name1 = self.X1[idx]\n",
        "        img_name2 = self.X2[idx]\n",
        "\n",
        "        image1 = Image.open(\"%s/%s\" % (self.query_dir, img_name1))\n",
        "        image2 = Image.open(\"%s/%s\" % (self.test_dir, img_name2))\n",
        "        image1 = T.ToTensor()(image1)\n",
        "        image2 = T.ToTensor()(image2)\n",
        "        image1 = F.interpolate(image1, size=128)  \n",
        "        image2 = F.interpolate(image2, size=128)  \n",
        "\n",
        "        sample = (image1, img_name1, image2, img_name2)\n",
        "        return sample\n",
        "\n",
        "class TestingDataset(Dataset):\n",
        "  def __init__(self, images, dir):\n",
        "      self.images = images\n",
        "      self.dir = dir\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "\n",
        "      img_name = self.images[idx]\n",
        "\n",
        "      image = Image.open(\"%s/%s\" % (self.dir, img_name))\n",
        "      image = T.ToTensor()(image)\n",
        "      image = F.interpolate(image, size=128)\n",
        "\n",
        "      sample = (image, img_name)\n",
        "      return sample"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP10JZT3HLQr"
      },
      "source": [
        "def getDataToEvaluate(test_dir, query_dir):\n",
        "    test_files = [f for f in listdir(test_dir)]\n",
        "    query_files = [f for f in listdir(query_dir)]\n",
        "\n",
        "    # test_files.sort()\n",
        "    # query_files.sort()\n",
        "\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    for query in query_files:\n",
        "        for test in test_files:\n",
        "            X1.append(query)\n",
        "            X2.append(test)\n",
        "    return X1, X2\n",
        "    \n",
        "def imshow(img,text=None,should_save=False):\n",
        "    npimg = img.cpu().numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()   "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkS1HHdAYQ60"
      },
      "source": [
        "def log_values(writer, step, loss, prefix):\n",
        "  writer.add_scalar(f\"{prefix}/loss\", loss, step)\n",
        "\n",
        "def extractTensors():\n",
        "\n",
        "  # Instantiates the model\n",
        "  net = initialize_alexnet(num_classes=56).to('cuda:0')\n",
        "  net = Siamese(net)\n",
        "  net.load_state_dict(torch.load(\"/content/drive/MyDrive/models/siamese_net_reid_resnet50_5epoch.pth\"))\n",
        "  net.to('cuda:0')\n",
        "  net.eval()\n",
        "  query = [f for f in listdir(\"./dataset/queries\")]\n",
        "  test = [f for f in listdir(\"./dataset/test\")]\n",
        "\n",
        "  query_images, test_images = getDataToEvaluate(test_dir=\"dataset/test\", query_dir=\"dataset/queries\")\n",
        "  #print(len(X1), len(X2))\n",
        "  '''\n",
        "  test_data = PeopleTestDataset(X1=query_images,\n",
        "                                X2=test_images,\n",
        "                                query_dir=\"dataset/queries\",\n",
        "                                test_dir=\"dataset/test\")\n",
        "  '''\n",
        "  testing_dataset = TestingDataset(images=test, dir=\"./dataset/test\")\n",
        "  test_dataloader = torch.utils.data.DataLoader(testing_dataset, 1, shuffle=False, num_workers=4) #before num_workers=4\n",
        "\n",
        "  query_dataset = TestingDataset(images=query, dir=\"./dataset/queries\")\n",
        "  query_dataloader = torch.utils.data.DataLoader(query_dataset, 1, shuffle=False, num_workers=2) #before num_workers=4\n",
        "\n",
        "  # For queries\n",
        "  if not os.path.exists('./dataset/query_tensors'):\n",
        "    os.mkdir(\"./dataset/query_tensors\")\n",
        "  for idx, (image, image_name) in enumerate(query_dataloader):\n",
        "    if (idx % 100 == 0):\n",
        "      print(idx)\n",
        "\n",
        "    # Compute the forward pass\n",
        "    tensor = image.to('cuda:0')\n",
        "    tensor_to_save = net.forward_one(tensor)\n",
        "    torch.save(tensor_to_save, \"./dataset/query_tensors/{}.ph\".format(image_name[0].split(\".\")[0]))\n",
        "\n",
        "  print(\"Query tensors extraction completed\\n\")\n",
        "\n",
        "  # For test\n",
        "  if not os.path.exists('./dataset/test_tensors'):\n",
        "    os.mkdir(\"./dataset/test_tensors\")\n",
        "  for idx, (image, image_name) in enumerate(test_dataloader):\n",
        "    if (idx % 100 == 0):\n",
        "      print(idx)\n",
        "\n",
        "    # Compute the forward pass\n",
        "    tensor = image.to('cuda:0')\n",
        "    tensor_to_save = net.forward_one(tensor)\n",
        "    torch.save(tensor_to_save, \"./dataset/test_tensors/{}.ph\".format(image_name[0].split(\".\")[0]))\n",
        "\n",
        "  print(\"Test tensors extraction completed\\n\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bisjaUeuuw6S"
      },
      "source": [
        "# import shutil\n",
        "# shutil.make_archive(\"query_tensors_archive\", 'zip', \"./dataset/query_tensors\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8YULodT2inl"
      },
      "source": [
        "# !unzip \"/content/query_tensors_archive.zip\" -d query_tensors\n",
        "# !unzip \"/content/test_tensors_archive.zip\" -d test_tensors"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAgt94Pk43bU"
      },
      "source": [
        "def main(threshold=0.001):\n",
        "  query_tensors = [f for f in listdir(\"./dataset/query_tensors\")]\n",
        "  query_images = [f for f in listdir(\"./dataset/queries\")]\n",
        "  test_tensors = [f for f in listdir(\"./dataset/test_tensors\")]\n",
        "  test_images = [f for f in listdir(\"./dataset/test\")]\n",
        "\n",
        "  query_tensors.sort()\n",
        "  query_images.sort()\n",
        "  test_tensors.sort()\n",
        "  test_images.sort()\n",
        "\n",
        "  test_tensors_cuda = []\n",
        "  for test in test_tensors:\n",
        "    test_tensor = torch.load(\"{}/{}\".format(\"./dataset/test_tensors\", test))\n",
        "    test_tensor.to('cuda:0')\n",
        "    test_tensors_cuda.append(test_tensor)\n",
        "\n",
        "  print(\"Test loaded\")\n",
        "\n",
        "  f = open(\"reid_results.txt\", \"w\")\n",
        "\n",
        "  for idxQ, query in enumerate(query_tensors):\n",
        "    #if idxQ == 20:\n",
        "    #  break\n",
        "\n",
        "    count = 0\n",
        "    #d#istance = 0\n",
        "    #concatenated = None\n",
        "\n",
        "    print(query, \"processing\")\n",
        "    query_tensor = torch.load(\"{}/{}\".format(\"./dataset/query_tensors\", query))\n",
        "    query_tensor.to('cuda:0')\n",
        "\n",
        "    to_print = \"{}:\".format(query_images[idxQ])\n",
        "\n",
        "    for idxT, test in enumerate(test_tensors_cuda):\n",
        "      euclidean_distance = F.pairwise_distance(query_tensor, test)\n",
        "      if euclidean_distance.item() < threshold:\n",
        "        to_print = \"{}{},\".format(to_print, test_images[idxT])\n",
        "        count+=1\n",
        "\n",
        "    if count != 1:\n",
        "      print(\"###### WARNING ###### {} with {} match\\n\".format(query_images[idxQ], count))\n",
        "\n",
        "\n",
        "    f.write(to_print[:-1])\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "  f.close()\n",
        "  print(\"Done\")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppQx1-td8oOc"
      },
      "source": [
        "extractTensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP2VMCfomdEX"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}